{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to implement the best subset , forward selection, and the lasso by Julia. Here are the results of implementation . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare the output of $\\beta$ coefficients and prediction of $y$ derived by our implementation and the function in R package `bestsubset` implemented by authors, using prostate data we have dealt with HW3 and HW4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>97 rows × 11 columns (omitted printing of 2 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>Column1</th><th>lcavol</th><th>lweight</th><th>age</th><th>lbph</th><th>svi</th><th>lcp</th><th>gleason</th><th>pgg45</th></tr><tr><th></th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"Int64\">Int64</th></tr></thead><tbody><tr><th>1</th><td>1</td><td>-0.579818</td><td>2.76946</td><td>50</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>2</th><td>2</td><td>-0.994252</td><td>3.31963</td><td>58</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>3</th><td>3</td><td>-0.510826</td><td>2.69124</td><td>74</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>7</td><td>20</td></tr><tr><th>4</th><td>4</td><td>-1.20397</td><td>3.28279</td><td>58</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>5</th><td>5</td><td>0.751416</td><td>3.43237</td><td>62</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>6</th><td>6</td><td>-1.04982</td><td>3.22883</td><td>50</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>7</th><td>7</td><td>0.737164</td><td>3.47352</td><td>64</td><td>0.615186</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>8</th><td>8</td><td>0.693147</td><td>3.53951</td><td>58</td><td>1.53687</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>9</th><td>9</td><td>-0.776529</td><td>3.53951</td><td>47</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>10</th><td>10</td><td>0.223144</td><td>3.24454</td><td>63</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>11</th><td>11</td><td>0.254642</td><td>3.60414</td><td>65</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>12</th><td>12</td><td>-1.34707</td><td>3.59868</td><td>63</td><td>1.26695</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>13</th><td>13</td><td>1.61343</td><td>3.02286</td><td>63</td><td>-1.38629</td><td>0</td><td>-0.597837</td><td>7</td><td>30</td></tr><tr><th>14</th><td>14</td><td>1.47705</td><td>2.99823</td><td>67</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>7</td><td>5</td></tr><tr><th>15</th><td>15</td><td>1.20597</td><td>3.44202</td><td>57</td><td>-1.38629</td><td>0</td><td>-0.430783</td><td>7</td><td>5</td></tr><tr><th>16</th><td>16</td><td>1.54116</td><td>3.06105</td><td>66</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>17</th><td>17</td><td>-0.415515</td><td>3.51601</td><td>70</td><td>1.24415</td><td>0</td><td>-0.597837</td><td>7</td><td>30</td></tr><tr><th>18</th><td>18</td><td>2.28849</td><td>3.64936</td><td>66</td><td>-1.38629</td><td>0</td><td>0.371564</td><td>6</td><td>0</td></tr><tr><th>19</th><td>19</td><td>-0.562119</td><td>3.26767</td><td>41</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>20</th><td>20</td><td>0.182322</td><td>3.82538</td><td>70</td><td>1.65823</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>21</th><td>21</td><td>1.1474</td><td>3.41936</td><td>59</td><td>-1.38629</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>22</th><td>22</td><td>2.05924</td><td>3.50104</td><td>60</td><td>1.47476</td><td>0</td><td>1.34807</td><td>7</td><td>20</td></tr><tr><th>23</th><td>23</td><td>-0.544727</td><td>3.37588</td><td>59</td><td>-0.798508</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>24</th><td>24</td><td>1.78171</td><td>3.45157</td><td>63</td><td>0.438255</td><td>0</td><td>1.17866</td><td>7</td><td>60</td></tr><tr><th>25</th><td>25</td><td>0.385262</td><td>3.6674</td><td>69</td><td>1.59939</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>26</th><td>26</td><td>1.44692</td><td>3.12457</td><td>68</td><td>0.300105</td><td>0</td><td>-1.38629</td><td>6</td><td>0</td></tr><tr><th>27</th><td>27</td><td>0.512824</td><td>3.71965</td><td>65</td><td>-1.38629</td><td>0</td><td>-0.798508</td><td>7</td><td>70</td></tr><tr><th>28</th><td>28</td><td>-0.400478</td><td>3.86598</td><td>67</td><td>1.81645</td><td>0</td><td>-1.38629</td><td>7</td><td>20</td></tr><tr><th>29</th><td>29</td><td>1.04028</td><td>3.12895</td><td>67</td><td>0.223144</td><td>0</td><td>0.0487902</td><td>7</td><td>80</td></tr><tr><th>30</th><td>30</td><td>2.40964</td><td>3.37588</td><td>65</td><td>-1.38629</td><td>0</td><td>1.61939</td><td>6</td><td>0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& Column1 & lcavol & lweight & age & lbph & svi & lcp & gleason & pgg45 & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Float64 & Float64 & Int64 & Float64 & Int64 & Float64 & Int64 & Int64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & -0.579818 & 2.76946 & 50 & -1.38629 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t2 & 2 & -0.994252 & 3.31963 & 58 & -1.38629 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t3 & 3 & -0.510826 & 2.69124 & 74 & -1.38629 & 0 & -1.38629 & 7 & 20 & $\\dots$ \\\\\n",
       "\t4 & 4 & -1.20397 & 3.28279 & 58 & -1.38629 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t5 & 5 & 0.751416 & 3.43237 & 62 & -1.38629 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t6 & 6 & -1.04982 & 3.22883 & 50 & -1.38629 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t7 & 7 & 0.737164 & 3.47352 & 64 & 0.615186 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t8 & 8 & 0.693147 & 3.53951 & 58 & 1.53687 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t9 & 9 & -0.776529 & 3.53951 & 47 & -1.38629 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t10 & 10 & 0.223144 & 3.24454 & 63 & -1.38629 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t11 & 11 & 0.254642 & 3.60414 & 65 & -1.38629 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t12 & 12 & -1.34707 & 3.59868 & 63 & 1.26695 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t13 & 13 & 1.61343 & 3.02286 & 63 & -1.38629 & 0 & -0.597837 & 7 & 30 & $\\dots$ \\\\\n",
       "\t14 & 14 & 1.47705 & 2.99823 & 67 & -1.38629 & 0 & -1.38629 & 7 & 5 & $\\dots$ \\\\\n",
       "\t15 & 15 & 1.20597 & 3.44202 & 57 & -1.38629 & 0 & -0.430783 & 7 & 5 & $\\dots$ \\\\\n",
       "\t16 & 16 & 1.54116 & 3.06105 & 66 & -1.38629 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t17 & 17 & -0.415515 & 3.51601 & 70 & 1.24415 & 0 & -0.597837 & 7 & 30 & $\\dots$ \\\\\n",
       "\t18 & 18 & 2.28849 & 3.64936 & 66 & -1.38629 & 0 & 0.371564 & 6 & 0 & $\\dots$ \\\\\n",
       "\t19 & 19 & -0.562119 & 3.26767 & 41 & -1.38629 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t20 & 20 & 0.182322 & 3.82538 & 70 & 1.65823 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t21 & 21 & 1.1474 & 3.41936 & 59 & -1.38629 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t22 & 22 & 2.05924 & 3.50104 & 60 & 1.47476 & 0 & 1.34807 & 7 & 20 & $\\dots$ \\\\\n",
       "\t23 & 23 & -0.544727 & 3.37588 & 59 & -0.798508 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t24 & 24 & 1.78171 & 3.45157 & 63 & 0.438255 & 0 & 1.17866 & 7 & 60 & $\\dots$ \\\\\n",
       "\t25 & 25 & 0.385262 & 3.6674 & 69 & 1.59939 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t26 & 26 & 1.44692 & 3.12457 & 68 & 0.300105 & 0 & -1.38629 & 6 & 0 & $\\dots$ \\\\\n",
       "\t27 & 27 & 0.512824 & 3.71965 & 65 & -1.38629 & 0 & -0.798508 & 7 & 70 & $\\dots$ \\\\\n",
       "\t28 & 28 & -0.400478 & 3.86598 & 67 & 1.81645 & 0 & -1.38629 & 7 & 20 & $\\dots$ \\\\\n",
       "\t29 & 29 & 1.04028 & 3.12895 & 67 & 0.223144 & 0 & 0.0487902 & 7 & 80 & $\\dots$ \\\\\n",
       "\t30 & 30 & 2.40964 & 3.37588 & 65 & -1.38629 & 0 & 1.61939 & 6 & 0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m97×11 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Column1 \u001b[0m\u001b[1m lcavol    \u001b[0m\u001b[1m lweight \u001b[0m\u001b[1m age   \u001b[0m\u001b[1m lbph      \u001b[0m\u001b[1m svi   \u001b[0m\u001b[1m lcp       \u001b[0m\u001b[1m gleaso\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64   \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m Int64 \u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │       1  -0.579818  2.76946     50  -1.38629       0  -1.38629          ⋯\n",
       "   2 │       2  -0.994252  3.31963     58  -1.38629       0  -1.38629\n",
       "   3 │       3  -0.510826  2.69124     74  -1.38629       0  -1.38629\n",
       "   4 │       4  -1.20397   3.28279     58  -1.38629       0  -1.38629\n",
       "   5 │       5   0.751416  3.43237     62  -1.38629       0  -1.38629          ⋯\n",
       "   6 │       6  -1.04982   3.22883     50  -1.38629       0  -1.38629\n",
       "   7 │       7   0.737164  3.47352     64   0.615186      0  -1.38629\n",
       "   8 │       8   0.693147  3.53951     58   1.53687       0  -1.38629\n",
       "   9 │       9  -0.776529  3.53951     47  -1.38629       0  -1.38629          ⋯\n",
       "  10 │      10   0.223144  3.24454     63  -1.38629       0  -1.38629\n",
       "  11 │      11   0.254642  3.60414     65  -1.38629       0  -1.38629\n",
       "  ⋮  │    ⋮         ⋮         ⋮       ⋮        ⋮        ⋮        ⋮         ⋮   ⋱\n",
       "  88 │      88   1.73166   3.36902     62  -1.38629       1   0.300105\n",
       "  89 │      89   2.80759   4.71805     65  -1.38629       1   2.46385          ⋯\n",
       "  90 │      90   1.56235   3.69511     76   0.936093      1   0.81093\n",
       "  91 │      91   3.24649   4.10182     68  -1.38629       0  -1.38629\n",
       "  92 │      92   2.5329    3.67757     61   1.34807       1  -1.38629\n",
       "  93 │      93   2.83027   3.8764      68  -1.38629       1   1.32176          ⋯\n",
       "  94 │      94   3.821     3.89691     44  -1.38629       1   2.16905\n",
       "  95 │      95   2.90745   3.39619     52  -1.38629       1   2.46385\n",
       "  96 │      96   2.88256   3.77391     68   1.55814       1   1.55814\n",
       "  97 │      97   3.47197   3.975       68   0.438255      1   2.90417          ⋯\n",
       "\u001b[36m                                                   4 columns and 76 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV, Random\n",
    "using DataFrames\n",
    "data = CSV.read(download(\"https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data\"), DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction_glmnet_df (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"bs.jl\")\n",
    "include(\"fs_new.jl\")\n",
    "include(\"lasso.jl\")\n",
    "include(\"lasso_glmnet.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Matrix(data[:, Not([\"Column1\",\"lpsa\",\"train\"])]) ;\n",
    "y = Vector{Float64}(data[:, \"lpsa\"]) ;\n",
    "\n",
    "using StatsBase\n",
    "using Random, InvertedIndices\n",
    "trainnum = Int(round(length(y) * 0.8))\n",
    "Random.seed!(1)\n",
    "trainobs = sample(1:length(y) ,trainnum, replace=false) ;\n",
    "y_train = y[trainobs]\n",
    "y_test = y[Not(trainobs)]\n",
    "X_train = X[trainobs, :]\n",
    "X_test = X[Not(trainobs), :] ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: RCall.jl: Loading required package: ggplot2\n",
      "│ Loading required package: glmnet\n",
      "│ Loading required package: Matrix\n",
      "│ Loaded glmnet 4.1-3\n",
      "│ Registered S3 method overwritten by 'bestsubset':\n",
      "│   method     from   \n",
      "│   predict.bs splines\n",
      "└ @ RCall /Users/changtaeyeong/.julia/packages/RCall/iMDW2/src/io.jl:160\n"
     ]
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(bestsubset)\n",
    "x <- $X_train\n",
    "y <- $y_train\n",
    "xtest <- $X_test\n",
    "bs.obj = bs(x,y)\n",
    "bs_beta = bs.obj$beta\n",
    "bs_prediction  = predict(bs.obj,newx=xtest) \n",
    "\"\"\"\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MathOptInterface"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Convex\n",
    "using Gurobi\n",
    "ENV[\"GRB_LICENSE_FILE\"]=\"/Users/changtaeyeong/gurobi.lic\" # set as YOUR path to license file\n",
    "const GRB_ENV = Gurobi.Env()\n",
    "const MOI = Convex.MOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n"
     ]
    }
   ],
   "source": [
    "my_pred, my_betas = prediction_bs(X_train, y_train, X_test) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×9 Matrix{Float64}:\n",
       " 0.0  0.702004  0.626947  0.48429    0.498498   …   0.554311     0.558751\n",
       " 0.0  0.0       0.698568  0.688224   0.758268       0.664061     0.65463\n",
       " 0.0  0.0       0.0       0.0       -0.0125847     -0.0221346   -0.0220767\n",
       " 0.0  0.0       0.0       0.0        0.0            0.0963484    0.0975977\n",
       " 0.0  0.0       0.0       0.707141   0.706083       0.826482     0.824548\n",
       " 0.0  0.0       0.0       0.0        0.0        …  -0.125668    -0.12749\n",
       " 0.0  0.0       0.0       0.0        0.0            0.0         -0.0324888\n",
       " 0.0  0.0       0.0       0.0        0.0            0.00418323   0.00479077"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@rget bs_beta   # Output from R `bestsubset` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×9 Matrix{Float64}:\n",
       " 0.0  0.702007  0.626955  0.484286   0.498494   …   0.554315     0.558757\n",
       " 0.0  0.0       0.698571  0.688214   0.758134       0.664139     0.654736\n",
       " 0.0  0.0       0.0       0.0       -0.0125815     -0.0221352   -0.022074\n",
       " 0.0  0.0       0.0       0.0        0.0            0.0963295    0.0975696\n",
       " 0.0  0.0       0.0       0.707164   0.706196       0.826515     0.824589\n",
       " 0.0  0.0       0.0       0.0        0.0        …  -0.125696    -0.127491\n",
       " 0.0  0.0       0.0       0.0        0.0            0.0         -0.0325582\n",
       " 0.0  0.0       0.0       0.0        0.0            0.00418272   0.00479027"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_betas    # Output by our julia implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×9 Matrix{Float64}:\n",
       " 2.55277  0.850303  0.826545  0.994239  …  0.878219  0.842446  0.844371\n",
       " 2.55277  2.06576   2.01956   1.93866      2.01185   1.96442   1.97542\n",
       " 2.55277  1.70492   1.53734   1.53214      1.40917   1.35673   1.36506\n",
       " 2.55277  1.25658   1.32657   1.40967      1.29695   1.3079    1.29882\n",
       " 2.55277  1.67626   1.91749   1.91211      1.92675   1.8582    1.86508\n",
       " 2.55277  2.79904   2.6591    2.42942   …  2.3672    2.46259   2.47746\n",
       " 2.55277  1.81873   1.93437   1.90167      1.94856   1.88225   1.89139\n",
       " 2.55277  2.56401   2.22077   2.04223      2.07552   2.00722   2.02451\n",
       " 2.55277  2.5473    2.57787   2.39722      1.98966   1.83237   1.78231\n",
       " 2.55277  2.5607    2.60764   2.424        2.27153   2.25453   2.23801\n",
       " 2.55277  2.71369   3.13004   2.9096    …  3.1478    3.12206   3.13181\n",
       " 2.55277  1.90828   1.99076   1.94021      1.96099   2.14343   2.16046\n",
       " 2.55277  2.43767   2.91518   2.75036      2.9303    2.9574    2.94178\n",
       " 2.55277  2.29328   2.48659   2.35555      2.55112   2.69408   2.69545\n",
       " 2.55277  3.00365   2.96159   2.68856      2.65056   2.61141   2.62444\n",
       " 2.55277  2.38641   3.21885   3.05928   …  3.07831   3.02028   2.99307\n",
       " 2.55277  2.40114   2.56487   3.11932      2.95083   2.86727   2.84967\n",
       " 2.55277  2.57872   2.19605   2.01508      1.98395   2.0172    2.02418\n",
       " 2.55277  3.42795   3.49098   3.12949      3.0915    3.20713   3.16335"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@rget bs_prediction # Output from R `bestsubset` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×9 Matrix{Float64}:\n",
       " 2.55277  0.850294  0.826525  0.994245  …  0.878247  0.842484  0.844405\n",
       " 2.55277  2.06576   2.01955   1.93866      2.01187   1.96443   1.97545\n",
       " 2.55277  1.70491   1.53733   1.53214      1.40921   1.35676   1.36511\n",
       " 2.55277  1.25657   1.32656   1.40968      1.29696   1.30786   1.29875\n",
       " 2.55277  1.67626   1.91749   1.91211      1.92677   1.85822   1.86512\n",
       " 2.55277  2.79904   2.6591    2.42941   …  2.36712   2.46251   2.47739\n",
       " 2.55277  1.81872   1.93436   1.90167      1.94858   1.88226   1.89142\n",
       " 2.55277  2.56401   2.22076   2.04223      2.07555   2.00721   2.02452\n",
       " 2.55277  2.5473    2.57787   2.39721      1.9896    1.83233   1.78227\n",
       " 2.55277  2.5607    2.60764   2.424        2.27156   2.25459   2.23806\n",
       " 2.55277  2.71369   3.13004   2.90958   …  3.14778   3.12211   3.13187\n",
       " 2.55277  1.90827   1.99075   1.9402       1.96095   2.14337   2.16036\n",
       " 2.55277  2.43767   2.91518   2.75035      2.93029   2.95745   2.94178\n",
       " 2.55277  2.29328   2.48659   2.35554      2.5511    2.69409   2.6954\n",
       " 2.55277  3.00365   2.96159   2.68855      2.65057   2.61148   2.62454\n",
       " 2.55277  2.38641   3.21885   3.05926   …  3.07828   3.02034   2.99313\n",
       " 2.55277  2.40114   2.56487   3.11934      2.95094   2.86733   2.84976\n",
       " 2.55277  2.57872   2.19605   2.01508      1.98392   2.01712   2.02408\n",
       " 2.55277  3.42795   3.49099   3.12948      3.09138   3.20705   3.16316"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pred    # Output by our julia implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n",
      "Academic license - for non-commercial use only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 4 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.436 s\u001b[22m\u001b[39m … \u001b[35m  1.585 s\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.62% … 0.59%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.500 s              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.62%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.505 s\u001b[22m\u001b[39m ± \u001b[32m71.399 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.62% ± 0.02%\n",
       "\n",
       "  \u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[34m█\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[34m█\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[32m▁\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m \u001b[39m▁\n",
       "  1.44 s\u001b[90m         Histogram: frequency by time\u001b[39m        1.59 s \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m83.65 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m119271\u001b[39m."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "bm = @benchmark prediction_bs($X_train, $y_train, $X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "Unit: milliseconds\n",
       "     expr      min       lq     mean   median       uq      max neval\n",
       " bs(x, y) 187.0863 196.4343 206.1053 202.0871 211.0265 297.8042   100\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "R\"\"\"\n",
    "library(microbenchmark)\n",
    "Rbm <- microbenchmark(bs(x,y))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(bestsubset)\n",
    "x <- $X_train\n",
    "y <- $y_train\n",
    "xtest <- $X_test\n",
    "fs.obj = fs(x,y)\n",
    "fs_beta = fs.obj$beta\n",
    "fs_prediction  = predict(fs.obj,newx=xtest) \n",
    "\"\"\"\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pred, my_betas = prediction_fs(X_train, y_train, X_test) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×9 Matrix{Float64}:\n",
       " 0.0  0.702004  0.626947  0.48429    0.498498   …   0.554311     0.558751\n",
       " 0.0  0.0       0.698568  0.688224   0.758268       0.664061     0.65463\n",
       " 0.0  0.0       0.0       0.0       -0.0125847     -0.0221346   -0.0220767\n",
       " 0.0  0.0       0.0       0.0        0.0            0.0963484    0.0975977\n",
       " 0.0  0.0       0.0       0.707141   0.706083       0.826482     0.824548\n",
       " 0.0  0.0       0.0       0.0        0.0        …  -0.125668    -0.12749\n",
       " 0.0  0.0       0.0       0.0        0.0            0.0         -0.0324888\n",
       " 0.0  0.0       0.0       0.0        0.0            0.00418323   0.00479077"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@rget fs_beta   # Output from R `bestsubset` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×9 Matrix{Float64}:\n",
       " 0.0  0.702004  0.626947  0.48429    0.498498   …   0.554311     0.558751\n",
       " 0.0  0.0       0.698568  0.688224   0.758268       0.664061     0.65463\n",
       " 0.0  0.0       0.0       0.0       -0.0125847     -0.0221346   -0.0220767\n",
       " 0.0  0.0       0.0       0.0        0.0            0.0963484    0.0975977\n",
       " 0.0  0.0       0.0       0.707141   0.706083       0.826482     0.824548\n",
       " 0.0  0.0       0.0       0.0        0.0        …  -0.125668    -0.12749\n",
       " 0.0  0.0       0.0       0.0        0.0            0.0         -0.0324888\n",
       " 0.0  0.0       0.0       0.0        0.0            0.00418323   0.00479077"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_betas    # Output by our julia implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×10 Matrix{Float64}:\n",
       " 2.55277  0.850303  0.826545  0.994239  …  0.842446  0.844371  0.844371\n",
       " 2.55277  2.06576   2.01956   1.93866      1.96442   1.97542   1.97542\n",
       " 2.55277  1.70492   1.53734   1.53214      1.35673   1.36506   1.36506\n",
       " 2.55277  1.25658   1.32657   1.40967      1.3079    1.29882   1.29882\n",
       " 2.55277  1.67626   1.91749   1.91211      1.8582    1.86508   1.86508\n",
       " 2.55277  2.79904   2.6591    2.42942   …  2.46259   2.47746   2.47746\n",
       " 2.55277  1.81873   1.93437   1.90167      1.88225   1.89139   1.89139\n",
       " 2.55277  2.56401   2.22077   2.04223      2.00722   2.02451   2.02451\n",
       " 2.55277  2.5473    2.57787   2.39722      1.83237   1.78231   1.78231\n",
       " 2.55277  2.5607    2.60764   2.424        2.25453   2.23801   2.23801\n",
       " 2.55277  2.71369   3.13004   2.9096    …  3.12206   3.13181   3.13181\n",
       " 2.55277  1.90828   1.99076   1.94021      2.14343   2.16046   2.16046\n",
       " 2.55277  2.43767   2.91518   2.75036      2.9574    2.94178   2.94178\n",
       " 2.55277  2.29328   2.48659   2.35555      2.69408   2.69545   2.69545\n",
       " 2.55277  3.00365   2.96159   2.68856      2.61141   2.62444   2.62444\n",
       " 2.55277  2.38641   3.21885   3.05928   …  3.02028   2.99307   2.99307\n",
       " 2.55277  2.40114   2.56487   3.11932      2.86727   2.84967   2.84967\n",
       " 2.55277  2.57872   2.19605   2.01508      2.0172    2.02418   2.02418\n",
       " 2.55277  3.42795   3.49098   3.12949      3.20713   3.16335   3.16335"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@rget fs_prediction # Output from R `bestsubset` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×9 Matrix{Float64}:\n",
       " 2.55277  0.850303  0.826545  0.994239  …  0.878219  0.842446  0.844371\n",
       " 2.55277  2.06576   2.01956   1.93866      2.01185   1.96442   1.97542\n",
       " 2.55277  1.70492   1.53734   1.53214      1.40917   1.35673   1.36506\n",
       " 2.55277  1.25658   1.32657   1.40967      1.29695   1.3079    1.29882\n",
       " 2.55277  1.67626   1.91749   1.91211      1.92675   1.8582    1.86508\n",
       " 2.55277  2.79904   2.6591    2.42942   …  2.3672    2.46259   2.47746\n",
       " 2.55277  1.81873   1.93437   1.90167      1.94856   1.88225   1.89139\n",
       " 2.55277  2.56401   2.22077   2.04223      2.07552   2.00722   2.02451\n",
       " 2.55277  2.5473    2.57787   2.39722      1.98966   1.83237   1.78231\n",
       " 2.55277  2.5607    2.60764   2.424        2.27153   2.25453   2.23801\n",
       " 2.55277  2.71369   3.13004   2.9096    …  3.1478    3.12206   3.13181\n",
       " 2.55277  1.90828   1.99076   1.94021      1.96099   2.14343   2.16046\n",
       " 2.55277  2.43767   2.91518   2.75036      2.9303    2.9574    2.94178\n",
       " 2.55277  2.29328   2.48659   2.35555      2.55112   2.69408   2.69545\n",
       " 2.55277  3.00365   2.96159   2.68856      2.65056   2.61141   2.62444\n",
       " 2.55277  2.38641   3.21885   3.05928   …  3.07831   3.02028   2.99307\n",
       " 2.55277  2.40114   2.56487   3.11932      2.95083   2.86727   2.84967\n",
       " 2.55277  2.57872   2.19605   2.01508      1.98395   2.0172    2.02418\n",
       " 2.55277  3.42795   3.49098   3.12949      3.0915    3.20713   3.16335"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pred    # Output by our julia implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m162.186 μs\u001b[22m\u001b[39m … \u001b[35m 20.761 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 97.74%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m208.839 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m263.563 μs\u001b[22m\u001b[39m ± \u001b[32m526.108 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m11.25% ±  6.72%\n",
       "\n",
       "  \u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[34m▇\u001b[39m\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[32m▄\u001b[39m\u001b[39m▄\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▃\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▁\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m \u001b[39m█\n",
       "  162 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        980 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m386.52 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m871\u001b[39m."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "bm = @benchmark prediction_fs($X_train, $y_train, $X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "Unit: milliseconds\n",
       "     expr     min       lq     mean   median      uq    max neval\n",
       " fs(x, y) 2.91032 2.991944 3.648699 3.212589 3.50117 11.146   100\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "R\"\"\"\n",
    "library(microbenchmark)\n",
    "Rbm <- microbenchmark(fs(x,y))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction_lasso (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"lasso.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(bestsubset)\n",
    "x <- $X_train\n",
    "y <- $y_train\n",
    "xtest <- $X_test\n",
    "lasso.obj = lasso(x,y)\n",
    "lasso_beta = as.matrix(coef(lasso.obj))[-1, ] # store betas except intercepts\n",
    "lasso_prediction  = predict(lasso.obj,newx=xtest)\n",
    "\"\"\"\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pred, my_betas , λs = prediction_lasso(X_train, y_train, X_test) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×50 Matrix{Float64}:\n",
       " 0.0  0.095222  0.177528  0.248177    0.30599    …   0.555562    0.555983\n",
       " 0.0  0.0       0.0       0.0         0.0            0.654804    0.654808\n",
       " 0.0  0.0       0.0       0.0         0.0           -0.0217357  -0.02178\n",
       " 0.0  0.0       0.0       0.0         0.0            0.0964112   0.0965667\n",
       " 0.0  0.0       0.0       0.00244138  0.0205741      0.819611    0.820316\n",
       " 0.0  0.0       0.0       0.0         0.0        …  -0.122831   -0.123443\n",
       " 0.0  0.0       0.0       0.0         0.0           -0.0254329  -0.0262866\n",
       " 0.0  0.0       0.0       0.0         0.0            0.0045573   0.00458614"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@rget lasso_beta   # Output from R `bestsubset` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×50 Matrix{Float64}:\n",
       " 0.0  0.120293  0.219974  0.301141   0.344738  …   0.558326     0.558389\n",
       " 0.0  0.0       0.0       0.0        0.0           0.654643     0.654647\n",
       " 0.0  0.0       0.0       0.0        0.0          -0.0220339   -0.022041\n",
       " 0.0  0.0       0.0       0.0        0.0           0.0974442    0.097469\n",
       " 0.0  0.0       0.0       0.0070502  0.129264      0.823847     0.823951\n",
       " 0.0  0.0       0.0       0.0        0.0       …  -0.126889    -0.126982\n",
       " 0.0  0.0       0.0       0.0        0.0          -0.0316365   -0.0317618\n",
       " 0.0  0.0       0.0       0.0        0.0           0.00476254   0.00476695"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_betas    # Output by our julia implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{S4Sxp}\n",
       "19 x 50 Matrix of class \"dgeMatrix\"\n",
       "            s1       s2       s3       s4       s5       s6       s7       s8\n",
       " [1,] 2.552768 2.321840 2.122236 1.950276 1.805421 1.698960 1.604411 1.521913\n",
       " [2,] 2.552768 2.486709 2.429611 2.379973 2.335217 2.287392 2.241852 2.201170\n",
       " [3,] 2.552768 2.437763 2.338358 2.252405 2.177932 2.112699 2.040561 1.973261\n",
       " [4,] 2.552768 2.376949 2.224978 2.093905 1.982508 1.895647 1.827008 1.769720\n",
       " [5,] 2.552768 2.433876 2.331111 2.242274 2.165440 2.098826 2.063951 2.040958\n",
       " [6,] 2.552768 2.586173 2.615047 2.639205 2.654837 2.642388 2.618868 2.594518\n",
       " [7,] 2.552768 2.453201 2.367139 2.292639 2.227538 2.167796 2.127096 2.095364\n",
       " [8,] 2.552768 2.554294 2.555612 2.556118 2.552395 2.528607 2.476071 2.420600\n",
       " [9,] 2.552768 2.552026 2.551385 2.550209 2.545109 2.520515 2.502452 2.487841\n",
       "[10,] 2.552768 2.553845 2.554775 2.554947 2.550951 2.527004 2.511045 2.498738\n",
       "[11,] 2.552768 2.574596 2.593463 2.609032 2.617635 2.601068 2.626305 2.660555\n",
       "[12,] 2.552768 2.465347 2.389784 2.324297 2.266571 2.211149 2.171094 2.138947\n",
       "[13,] 2.552768 2.537157 2.523662 2.511453 2.497325 2.467443 2.486825 2.517798\n",
       "[14,] 2.552768 2.517570 2.487146 2.460405 2.434386 2.397537 2.384104 2.378287\n",
       "[15,] 2.552768 2.613927 2.666789 2.711539 2.744022 2.741443 2.735740 2.729706\n",
       "[16,] 2.552768 2.530203 2.510698 2.493330 2.474980 2.442625 2.493251 2.561730\n",
       "[17,] 2.552768 2.532202 2.514425 2.500981 2.501977 2.565219 2.634306 2.698573\n",
       "[18,] 2.552768 2.556289 2.559332 2.561319 2.558807 2.535729 2.480102 2.420792\n",
       "[19,] 2.552768 2.671481 2.774091 2.861542 2.928968 2.946859 2.968889 2.989980\n",
       "            s9      s10      s11      s12      s13      s14      s15      s16\n",
       " [1,] 1.450349 1.388481 1.335005 1.288754 1.248781 1.213825 1.180213 1.145774\n",
       " [2,] 2.165564 2.134785 2.108182 2.085184 2.065305 2.048398 2.035931 2.028503\n",
       " [3,] 1.913430 1.861710 1.817006 1.778355 1.744948 1.715714 1.687533 1.658602\n",
       " [4,] 1.720890 1.678676 1.642188 1.610628 1.583353 1.560264 1.544020 1.535726\n",
       " [5,] 2.023486 2.008379 1.995321 1.984021 1.974256 1.966286 1.963029 1.965845\n",
       " [6,] 2.572118 2.552762 2.536031 2.521581 2.509089 2.498515 2.491212 2.487810\n",
       " [7,] 2.069095 2.046385 2.026755 2.009779 1.995107 1.982963 1.976661 1.977740\n",
       " [8,] 2.369273 2.324912 2.286567 2.253431 2.224789 2.200388 2.182157 2.170912\n",
       " [9,] 2.475547 2.464922 2.455739 2.447807 2.440950 2.434740 2.427167 2.417185\n",
       "[10,] 2.488598 2.479836 2.472263 2.465723 2.460069 2.454576 2.445079 2.429455\n",
       "[11,] 2.694332 2.723531 2.748770 2.770593 2.789454 2.806156 2.823797 2.844056\n",
       "[12,] 2.111992 2.088691 2.068550 2.051134 2.036081 2.023587 2.016829 2.017282\n",
       "[13,] 2.549342 2.576609 2.600177 2.620550 2.638159 2.653771 2.670366 2.689538\n",
       "[14,] 2.375203 2.372537 2.370233 2.368241 2.366520 2.365351 2.366865 2.372109\n",
       "[15,] 2.724118 2.719294 2.715125 2.711536 2.708431 2.705178 2.697962 2.684879\n",
       "[16,] 2.629219 2.687553 2.737975 2.781558 2.819229 2.851972 2.881718 2.909637\n",
       "[17,] 2.755654 2.804983 2.847621 2.884456 2.916297 2.943272 2.962126 2.971383\n",
       "[18,] 2.365757 2.318191 2.277076 2.241546 2.210834 2.184773 2.166139 2.156159\n",
       "[19,] 3.008894 3.025252 3.039392 3.051636 3.062216 3.071624 3.081990 3.094499\n",
       "           s17      s18      s19      s20      s21      s22       s23       s24\n",
       " [1,] 1.114899 1.088151 1.064792 1.042724 1.022909 1.005535 0.9906115 0.9776038\n",
       " [2,] 2.022788 2.017696 2.012833 2.004227 1.994597 1.985336 1.9773456 1.9704294\n",
       " [3,] 1.632643 1.609616 1.587928 1.559406 1.532522 1.508481 1.4877431 1.4697712\n",
       " [4,] 1.529780 1.523680 1.515487 1.497442 1.482472 1.470177 1.4596468 1.4504378\n",
       " [5,] 1.969473 1.971955 1.972109 1.960924 1.948474 1.936697 1.9265865 1.9177698\n",
       " [6,] 2.485470 2.483525 2.482106 2.487482 2.496792 2.506890 2.5155595 2.5231077\n",
       " [7,] 1.980050 1.981468 1.980939 1.970146 1.958019 1.946480 1.9365582 1.9279297\n",
       " [8,] 2.162129 2.153731 2.144079 2.122060 2.099445 2.078499 2.0603848 2.0447609\n",
       " [9,] 2.407833 2.398351 2.385976 2.355587 2.326880 2.301386 2.2793621 2.2602985\n",
       "[10,] 2.414392 2.400491 2.385845 2.360077 2.335712 2.313964 2.2951590 2.2788912\n",
       "[11,] 2.862615 2.879269 2.895504 2.914827 2.929854 2.941877 2.9522313 2.9612065\n",
       "[12,] 2.019001 2.020549 2.022062 2.031554 2.046107 2.061560 2.0749311 2.0864585\n",
       "[13,] 2.707125 2.722652 2.737037 2.753039 2.766737 2.778417 2.7885031 2.7972091\n",
       "[14,] 2.377469 2.382699 2.389004 2.405576 2.423312 2.439998 2.4543991 2.4668538\n",
       "[15,] 2.672123 2.660804 2.650172 2.634307 2.617863 2.602457 2.5890854 2.5775743\n",
       "[16,] 2.934242 2.955301 2.972860 2.982776 2.989321 2.994146 2.9983365 3.0018949\n",
       "[17,] 2.977924 2.982679 2.984050 2.969561 2.953129 2.937513 2.9241390 2.9124554\n",
       "[18,] 2.148808 2.141941 2.134492 2.123917 2.116269 2.110464 2.1054194 2.1011040\n",
       "[19,] 3.106040 3.116263 3.125889 3.143902 3.165017 3.185637 3.2033561 3.2187614\n",
       "            s25       s26      s27       s28       s29       s30       s31\n",
       " [1,] 0.9658833 0.9522424 0.937302 0.9244012 0.9132818 0.9036732 0.8953563\n",
       " [2,] 1.9646736 1.9623058 1.962620 1.9628490 1.9630602 1.9632439 1.9633970\n",
       " [3,] 1.4542118 1.4408757 1.429459 1.4195915 1.4110646 1.4036945 1.3973230\n",
       " [4,] 1.4418866 1.4287781 1.412296 1.3981450 1.3859044 1.3753232 1.3661820\n",
       " [5,] 1.9100691 1.9032117 1.897115 1.8918434 1.8872808 1.8833365 1.8799289\n",
       " [6,] 2.5291023 2.5267388 2.517862 2.5103962 2.5039147 2.4983101 2.4934804\n",
       " [7,] 1.9204930 1.9147229 1.910338 1.9065343 1.9032415 1.9003948 1.8979355\n",
       " [8,] 2.0317235 2.0246633 2.022356 2.0203244 2.0185484 2.0170116 2.0156901\n",
       " [9,] 2.2421571 2.2054105 2.154577 2.1110931 2.0733052 2.0406252 2.0124604\n",
       "[10,] 2.2653563 2.2590407 2.258455 2.2579143 2.2574545 2.2570578 2.2567114\n",
       "[11,] 2.9696044 2.9839382 3.002728 3.0188675 3.0328607 3.0449597 3.0554000\n",
       "[12,] 2.0962721 2.1035872 2.108873 2.1134869 2.1175429 2.1210546 2.1240664\n",
       "[13,] 2.8053364 2.8195165 2.838256 2.8543496 2.8683226 2.8804058 2.8908252\n",
       "[14,] 2.4784523 2.4985761 2.525121 2.5479044 2.5677208 2.5848601 2.5996269\n",
       "[15,] 2.5683722 2.5676918 2.573675 2.5787829 2.5832076 2.5870330 2.5903351\n",
       "[16,] 3.0049301 3.0072486 3.008990 3.0105349 3.0118575 3.0129995 3.0139919\n",
       "[17,] 2.9023412 2.8957753 2.892083 2.8887395 2.8858294 2.8833122 2.8811394\n",
       "[18,] 2.0971504 2.0897931 2.079858 2.0713952 2.0640465 2.0576917 2.0522139\n",
       "[19,] 3.2316091 3.2350430 3.231057 3.2278564 3.2250491 3.2226191 3.2205391\n",
       "            s32       s33      s34       s35       s36       s37       s38\n",
       " [1,] 0.8881481 0.8819484 0.876590 0.8719448 0.8679208 0.8644642 0.8615458\n",
       " [2,] 1.9635199 1.9636410 1.963746 1.9638283 1.9638939 1.9639640 1.9648063\n",
       " [3,] 1.3918140 1.3870551 1.382942 1.3793850 1.3763098 1.3736539 1.3719231\n",
       " [4,] 1.3582884 1.3514534 1.345545 1.3404476 1.3360472 1.3322293 1.3281782\n",
       " [5,] 1.8769863 1.8744385 1.872236 1.8703344 1.8686917 1.8672691 1.8665384\n",
       " [6,] 2.4893302 2.4857044 2.482570 2.4798861 2.4775829 2.4755511 2.4746345\n",
       " [7,] 1.8958118 1.8939731 1.892384 1.8910106 1.8898243 1.8887978 1.8885677\n",
       " [8,] 2.0145589 2.0135636 2.012703 2.0119658 2.0113332 2.0107757 2.0115364\n",
       " [9,] 1.9882520 1.9671126 1.948837 1.9331555 1.9196763 1.9078423 1.8939449\n",
       "[10,] 2.2564062 2.2561516 2.255932 2.2557360 2.2555633 2.2554228 2.2541529\n",
       "[11,] 3.0643952 3.0722159 3.078977 3.0847955 3.0898090 3.0941818 3.0987067\n",
       "[12,] 2.1266310 2.1289088 2.130879 2.1325554 2.1339874 2.1352664 2.1373742\n",
       "[13,] 2.8997903 2.9076040 2.914359 2.9201640 2.9251599 2.9295312 2.9322298\n",
       "[14,] 2.6123119 2.6234005 2.632987 2.6412107 2.6482778 2.6544858 2.6598938\n",
       "[15,] 2.5931820 2.5956542 2.597791 2.5996309 2.6012161 2.6025983 2.6047574\n",
       "[16,] 3.0148583 3.0155936 3.016229 3.0167855 3.0172716 3.0176798 3.0161501\n",
       "[17,] 2.8792667 2.8776400 2.876234 2.8750155 2.8739612 2.8730543 2.8712863\n",
       "[18,] 2.0475041 2.0433937 2.039840 2.0367917 2.0341715 2.0318703 2.0302354\n",
       "[19,] 3.2187749 3.2171967 3.215832 3.2146859 3.2137173 3.2128260 3.2087503\n",
       "            s39       s40       s41       s42       s43       s44       s45\n",
       " [1,] 0.8591603 0.8571547 0.8553763 0.8538312 0.8525307 0.8514016 0.8504063\n",
       " [2,] 1.9660408 1.9673258 1.9683606 1.9692369 1.9700497 1.9707383 1.9712923\n",
       " [3,] 1.3708244 1.3700497 1.3693224 1.3686812 1.3681691 1.3677174 1.3672983\n",
       " [4,] 1.3243264 1.3208535 1.3178907 1.3153429 1.3131132 1.3111979 1.3095710\n",
       " [5,] 1.8662188 1.8660771 1.8659107 1.8657584 1.8656542 1.8655572 1.8654536\n",
       " [6,] 2.4746046 2.4749541 2.4751923 2.4753836 2.4756204 2.4758208 2.4759602\n",
       " [7,] 1.8887846 1.8891523 1.8894128 1.8896257 1.8898478 1.8900300 1.8901593\n",
       " [8,] 2.0129708 2.0145540 2.0158310 2.0169123 2.0179113 2.0187575 2.0194387\n",
       " [9,] 1.8796616 1.8663858 1.8553244 1.8458680 1.8373886 1.8301424 1.8241158\n",
       "[10,] 2.2522991 2.2503582 2.2487692 2.2474165 2.2461768 2.2451197 2.2442537\n",
       "[11,] 3.1030394 3.1069546 3.1102656 3.1131077 3.1156190 3.1177736 3.1195916\n",
       "[12,] 2.1400867 2.1428319 2.1450566 2.1469449 2.1487078 2.1502105 2.1514296\n",
       "[13,] 2.9338555 2.9349297 2.9359104 2.9367693 2.9374711 2.9380844 2.9386398\n",
       "[14,] 2.6646908 2.6688655 2.6723861 2.6754057 2.6780894 2.6803915 2.6823280\n",
       "[15,] 2.6071930 2.6095440 2.6115043 2.6131793 2.6146807 2.6159634 2.6170289\n",
       "[16,] 3.0135629 3.0107684 3.0085237 3.0066254 3.0048521 3.0033498 3.0021460\n",
       "[17,] 2.8688389 2.8662834 2.8641797 2.8623884 2.8607290 2.8593072 2.8581399\n",
       "[18,] 2.0292001 2.0284985 2.0278672 2.0273162 2.0268699 2.0264842 2.0261387\n",
       "[19,] 3.2033159 3.1978184 3.1933500 3.1895554 3.1860845 3.1831408 3.1807497\n",
       "            s46       s47       s48      s49       s50\n",
       " [1,] 0.8495451 0.8489281 0.8482851 0.847670 0.8471997\n",
       " [2,] 1.9717508 1.9722440 1.9726100 1.972900 1.9732028\n",
       " [3,] 1.3669246 1.3666917 1.3664270 1.366167 1.3659862\n",
       " [4,] 1.3081876 1.3070000 1.3059431 1.305005 1.3041847\n",
       " [5,] 1.8653568 1.8653402 1.8652751 1.865194 1.8651619\n",
       " [6,] 2.4760725 2.4763283 2.4764399 2.476467 2.4765339\n",
       " [7,] 1.8902586 1.8904202 1.8905082 1.890561 1.8906482\n",
       " [8,] 2.0199989 2.0205575 2.0210118 2.021396 2.0217706\n",
       " [9,] 1.8190287 1.8140905 1.8101639 1.806913 1.8037837\n",
       "[10,] 2.2435253 2.2427525 2.2421822 2.241738 2.2412853\n",
       "[11,] 3.1211376 3.1225567 3.1237377 3.124742 3.1256631\n",
       "[12,] 2.1524554 2.1536482 2.1544562 2.155034 2.1556672\n",
       "[13,] 2.9391301 2.9394858 2.9398332 2.940156 2.9404093\n",
       "[14,] 2.6839766 2.6855593 2.6868159 2.687850 2.6888290\n",
       "[15,] 2.6179235 2.6187537 2.6194535 2.620056 2.6206102\n",
       "[16,] 3.0011520 3.0000688 2.9992678 2.998638 2.9979809\n",
       "[17,] 2.8571543 2.8560828 2.8552992 2.854708 2.8541239\n",
       "[18,] 2.0258378 2.0256328 2.0254226 2.025216 2.0250434\n",
       "[19,] 3.1787622 3.1767143 3.1751504 3.173879 3.1725728\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@rget lasso_prediction # Output from R `bestsubset` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×50 Matrix{Float64}:\n",
       " 2.55277  2.26104  2.0193   1.82065  1.68358  …  0.844949  0.844851  0.844778\n",
       " 2.55277  2.46932  2.40016  2.34205  2.28047     1.97506   1.97512   1.97516\n",
       " 2.55277  2.40748  2.28709  2.18726  2.10326     1.36527   1.36523   1.3652\n",
       " 2.55277  2.33066  2.14661  1.99493  1.88309     1.29982   1.29965   1.29952\n",
       " 2.55277  2.40257  2.27811  2.17496  2.08919     1.86512   1.86511   1.86511\n",
       " 2.55277  2.59497  2.62994  2.6566   2.64056  …  2.47738   2.4774    2.47741\n",
       " 2.55277  2.42699  2.32276  2.23608  2.15915     1.89129   1.8913    1.89131\n",
       " 2.55277  2.5547   2.55629  2.55578  2.52515     2.02404   2.02412   2.02417\n",
       " 2.55277  2.55183  2.55105  2.54861  2.51694     1.78603   1.7854    1.78493\n",
       " 2.55277  2.55413  2.55525  2.55436  2.52352     2.23855   2.23846   2.23839\n",
       " 2.55277  2.58034  2.60319  2.61999  2.59865  …  3.13071   3.1309    3.13104\n",
       " 2.55277  2.44233  2.35082  2.27449  2.20313     2.15973   2.15986   2.15996\n",
       " 2.55277  2.53305  2.5167   2.50159  2.4631      2.9415    2.94155   2.94159\n",
       " 2.55277  2.5083   2.47146  2.43965  2.39219     2.69431   2.69451   2.69466\n",
       " 2.55277  2.63003  2.69405  2.74437  2.74104     2.62376   2.62388   2.62396\n",
       " 2.55277  2.52426  2.50064  2.4796   2.43793  …  2.99386   2.99373   2.99363\n",
       " 2.55277  2.52679  2.50526  2.49297  2.57443     2.85036   2.85024   2.85015\n",
       " 2.55277  2.55722  2.5609   2.5621   2.53237     2.02438   2.02434   2.02432\n",
       " 2.55277  2.70274  2.82701  2.92639  2.94941     3.16492   3.16466   3.16447"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pred    # Output by our julia implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 188 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m18.683 ms\u001b[22m\u001b[39m … \u001b[35m41.622 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 33.45%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m24.390 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m26.696 ms\u001b[22m\u001b[39m ± \u001b[32m 5.737 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m16.67% ± 15.54%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m \u001b[39m█\u001b[39m▃\u001b[39m▇\u001b[39m▄\u001b[39m▅\u001b[39m▄\u001b[39m \u001b[39m▄\u001b[39m \u001b[39m \u001b[39m \u001b[34m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m \u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▃\u001b[39m▃\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[34m▃\u001b[39m\u001b[39m▅\u001b[39m▃\u001b[39m▃\u001b[39m▅\u001b[39m▃\u001b[39m▁\u001b[32m▁\u001b[39m\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m▃\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▃\u001b[39m█\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▁\u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▅\u001b[39m \u001b[39m▃\n",
       "  18.7 ms\u001b[90m         Histogram: frequency by time\u001b[39m        38.9 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m33.39 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m315411\u001b[39m."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "bm = @benchmark prediction_lasso($X_train, $y_train, $X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "Unit: milliseconds\n",
       "        expr      min       lq     mean   median       uq      max neval\n",
       " lasso(x, y) 1.010305 1.016809 1.070416 1.023006 1.059173 1.643793   100\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(microbenchmark)\n",
    "Rbm <- microbenchmark(lasso(x,y))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relaxed Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(bestsubset)\n",
    "x <- $X_train\n",
    "y <- $y_train\n",
    "xtest <- $X_test\n",
    "relaxlasso.obj = lasso(x,y, nrelax = 3)\n",
    "relaxlasso_beta = as.matrix(coef(relaxlasso.obj))[-1, ] # store betas except intercepts\n",
    "relaxlasso_prediction  = predict(relaxlasso.obj,newx=xtest)\n",
    "\"\"\"\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pred, my_betas , λs , γs = prediction_lasso(X_train, y_train, X_test, nrelax = 3) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×150 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  0.095222  0.398613  0.702004  …   0.557367     0.558751\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.654719     0.65463\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0          -0.0219284   -0.0220767\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.0970822    0.0975977\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.822432     0.824548\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0       …  -0.125466    -0.12749\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0          -0.0293877   -0.0324888\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.00468846   0.00479077"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@rget relaxlasso_beta  # Output from R `bestsubset` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×150 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  0.120293  0.411148  0.702004  …   0.55857      0.558751\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.654638     0.65463\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0          -0.0220589   -0.0220767\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.0975334    0.0975977\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.824249     0.824548\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0       …  -0.127236    -0.12749\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0          -0.0321253   -0.0324888\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.00477886   0.00479077"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×150 Matrix{Float64}:\n",
       " 2.55277  2.55277  2.55277  2.32184  1.58607  …  0.8472   0.845785  0.844371\n",
       " 2.55277  2.55277  2.55277  2.48671  2.27624     1.9732   1.97431   1.97542\n",
       " 2.55277  2.55277  2.55277  2.43776  2.07134     1.36599  1.36552   1.36506\n",
       " 2.55277  2.55277  2.55277  2.37695  1.81676     1.30418  1.3015    1.29882\n",
       " 2.55277  2.55277  2.55277  2.43388  2.05507     1.86516  1.86512   1.86508\n",
       " 2.55277  2.55277  2.55277  2.58617  2.69261  …  2.47653  2.477     2.47746\n",
       " 2.55277  2.55277  2.55277  2.4532   2.13596     1.89065  1.89102   1.89139\n",
       " 2.55277  2.55277  2.55277  2.55429  2.55915     2.02177  2.02314   2.02451\n",
       " 2.55277  2.55277  2.55277  2.55203  2.54966     1.80378  1.79305   1.78231\n",
       " 2.55277  2.55277  2.55277  2.55384  2.55727     2.24129  2.23965   2.23801\n",
       " 2.55277  2.55277  2.55277  2.5746   2.64414  …  3.12566  3.12874   3.13181\n",
       " 2.55277  2.55277  2.55277  2.46535  2.18681     2.15567  2.15806   2.16046\n",
       " 2.55277  2.55277  2.55277  2.53716  2.48741     2.94041  2.9411    2.94178\n",
       " 2.55277  2.55277  2.55277  2.51757  2.40542     2.68883  2.69214   2.69545\n",
       " 2.55277  2.55277  2.55277  2.61393  2.80879     2.62061  2.62252   2.62444\n",
       " 2.55277  2.55277  2.55277  2.5302   2.45831  …  2.99798  2.99552   2.99307\n",
       " 2.55277  2.55277  2.55277  2.5322   2.46667     2.85412  2.8519    2.84967\n",
       " 2.55277  2.55277  2.55277  2.55629  2.56751     2.02504  2.02461   2.02418\n",
       " 2.55277  2.55277  2.55277  2.67148  3.04972     3.17257  3.16796   3.16335"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@rget relaxlasso_prediction # Output from R `bestsubset` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×150 Matrix{Float64}:\n",
       " 2.55277  2.55277  2.55277  2.26104  1.55567  …  0.844778  0.844574  0.844371\n",
       " 2.55277  2.55277  2.55277  2.46932  2.26754     1.97516   1.97529   1.97542\n",
       " 2.55277  2.55277  2.55277  2.40748  2.0562      1.3652    1.36513   1.36506\n",
       " 2.55277  2.55277  2.55277  2.33066  1.79362     1.29952   1.29917   1.29882\n",
       " 2.55277  2.55277  2.55277  2.40257  2.03942     1.86511   1.86509   1.86508\n",
       " 2.55277  2.55277  2.55277  2.59497  2.697    …  2.47741   2.47744   2.47746\n",
       " 2.55277  2.55277  2.55277  2.42699  2.12286     1.89131   1.89135   1.89139\n",
       " 2.55277  2.55277  2.55277  2.5547   2.55935     2.02417   2.02434   2.02451\n",
       " 2.55277  2.55277  2.55277  2.55183  2.54956     1.78493   1.78362   1.78231\n",
       " 2.55277  2.55277  2.55277  2.55413  2.55742     2.23839   2.2382    2.23801\n",
       " 2.55277  2.55277  2.55277  2.58034  2.64702  …  3.13104   3.13142   3.13181\n",
       " 2.55277  2.55277  2.55277  2.44233  2.1753      2.15996   2.16021   2.16046\n",
       " 2.55277  2.55277  2.55277  2.53305  2.48536     2.94159   2.94169   2.94178\n",
       " 2.55277  2.55277  2.55277  2.5083   2.40079     2.69466   2.69506   2.69545\n",
       " 2.55277  2.55277  2.55277  2.63003  2.81684     2.62396   2.6242    2.62444\n",
       " 2.55277  2.55277  2.55277  2.52426  2.45534  …  2.99363   2.99335   2.99307\n",
       " 2.55277  2.55277  2.55277  2.52679  2.46397     2.85015   2.84991   2.84967\n",
       " 2.55277  2.55277  2.55277  2.55722  2.56797     2.02432   2.02425   2.02418\n",
       " 2.55277  2.55277  2.55277  2.70274  3.06534     3.16447   3.16391   3.16335"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pred    # Output by our julia implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 163 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m21.375 ms\u001b[22m\u001b[39m … \u001b[35m58.413 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m 0.00% … 22.30%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m31.918 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m30.675 ms\u001b[22m\u001b[39m ± \u001b[32m 7.017 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m16.06% ± 14.15%\n",
       "\n",
       "  \u001b[39m \u001b[39m▄\u001b[39m▅\u001b[39m▂\u001b[39m▂\u001b[39m▅\u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[34m▂\u001b[39m\u001b[39m▂\u001b[39m▅\u001b[39m▇\u001b[39m▄\u001b[39m▂\u001b[39m▅\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▅\u001b[39m▇\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[32m▃\u001b[39m\u001b[39m▇\u001b[39m▇\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m \u001b[39m▃\n",
       "  21.4 ms\u001b[90m         Histogram: frequency by time\u001b[39m        49.6 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m37.53 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m319841\u001b[39m."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "bm = @benchmark prediction_lasso($X_train, $y_train, $X_test, nrelax=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "Unit: milliseconds\n",
       "                    expr      min       lq    mean   median       uq     max\n",
       " lasso(x, y, nrelax = 3) 1.013545 1.145029 1.53325 1.351107 1.701205 3.57826\n",
       " neval\n",
       "   100\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(microbenchmark)\n",
    "Rbm <- microbenchmark(lasso(x,y, nrelax = 3))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso & Relaxed Lasso using glmnet wrapper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(bestsubset)\n",
    "x <- $X_train\n",
    "y <- $y_train\n",
    "xtest <- $X_test\n",
    "lasso.obj = lasso(x,y)\n",
    "lasso_beta = as.matrix(coef(lasso.obj))[-1, ] # store betas except intercepts\n",
    "lasso_prediction  = predict(lasso.obj,newx=xtest)\n",
    "\"\"\"\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pred, my_betas , λs = prediction_glmnet(X_train, y_train, X_test, nlambda = 50) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×50 Matrix{Float64}:\n",
       " 0.0  0.095222  0.177528  0.248177    0.30599    …   0.555562    0.555983\n",
       " 0.0  0.0       0.0       0.0         0.0            0.654804    0.654808\n",
       " 0.0  0.0       0.0       0.0         0.0           -0.0217357  -0.02178\n",
       " 0.0  0.0       0.0       0.0         0.0            0.0964112   0.0965667\n",
       " 0.0  0.0       0.0       0.00244138  0.0205741      0.819611    0.820316\n",
       " 0.0  0.0       0.0       0.0         0.0        …  -0.122831   -0.123443\n",
       " 0.0  0.0       0.0       0.0         0.0           -0.0254329  -0.0262866\n",
       " 0.0  0.0       0.0       0.0         0.0            0.0045573   0.00458614"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@rget lasso_beta   # Output from R `bestsubset` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×39 CompressedPredictorMatrix:\n",
       " 0.0  0.120293  0.219974  0.301155    0.344767  …   0.555429     0.555983\n",
       " 0.0  0.0       0.0       0.0         0.0           0.654803     0.654808\n",
       " 0.0  0.0       0.0       0.0         0.0          -0.0217216   -0.02178\n",
       " 0.0  0.0       0.0       0.0         0.0           0.0963619    0.0965667\n",
       " 0.0  0.0       0.0       0.00702739  0.129219      0.819388     0.820316\n",
       " 0.0  0.0       0.0       0.0         0.0       …  -0.122637    -0.123443\n",
       " 0.0  0.0       0.0       0.0         0.0          -0.0251617   -0.0262866\n",
       " 0.0  0.0       0.0       0.0         0.0           0.00454813   0.00458614"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_betas    # Output by our julia implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{S4Sxp}\n",
       "19 x 50 Matrix of class \"dgeMatrix\"\n",
       "            s1       s2       s3       s4       s5       s6       s7       s8\n",
       " [1,] 2.552768 2.321840 2.122236 1.950276 1.805421 1.698960 1.604411 1.521913\n",
       " [2,] 2.552768 2.486709 2.429611 2.379973 2.335217 2.287392 2.241852 2.201170\n",
       " [3,] 2.552768 2.437763 2.338358 2.252405 2.177932 2.112699 2.040561 1.973261\n",
       " [4,] 2.552768 2.376949 2.224978 2.093905 1.982508 1.895647 1.827008 1.769720\n",
       " [5,] 2.552768 2.433876 2.331111 2.242274 2.165440 2.098826 2.063951 2.040958\n",
       " [6,] 2.552768 2.586173 2.615047 2.639205 2.654837 2.642388 2.618868 2.594518\n",
       " [7,] 2.552768 2.453201 2.367139 2.292639 2.227538 2.167796 2.127096 2.095364\n",
       " [8,] 2.552768 2.554294 2.555612 2.556118 2.552395 2.528607 2.476071 2.420600\n",
       " [9,] 2.552768 2.552026 2.551385 2.550209 2.545109 2.520515 2.502452 2.487841\n",
       "[10,] 2.552768 2.553845 2.554775 2.554947 2.550951 2.527004 2.511045 2.498738\n",
       "[11,] 2.552768 2.574596 2.593463 2.609032 2.617635 2.601068 2.626305 2.660555\n",
       "[12,] 2.552768 2.465347 2.389784 2.324297 2.266571 2.211149 2.171094 2.138947\n",
       "[13,] 2.552768 2.537157 2.523662 2.511453 2.497325 2.467443 2.486825 2.517798\n",
       "[14,] 2.552768 2.517570 2.487146 2.460405 2.434386 2.397537 2.384104 2.378287\n",
       "[15,] 2.552768 2.613927 2.666789 2.711539 2.744022 2.741443 2.735740 2.729706\n",
       "[16,] 2.552768 2.530203 2.510698 2.493330 2.474980 2.442625 2.493251 2.561730\n",
       "[17,] 2.552768 2.532202 2.514425 2.500981 2.501977 2.565219 2.634306 2.698573\n",
       "[18,] 2.552768 2.556289 2.559332 2.561319 2.558807 2.535729 2.480102 2.420792\n",
       "[19,] 2.552768 2.671481 2.774091 2.861542 2.928968 2.946859 2.968889 2.989980\n",
       "            s9      s10      s11      s12      s13      s14      s15      s16\n",
       " [1,] 1.450349 1.388481 1.335005 1.288754 1.248781 1.213825 1.180213 1.145774\n",
       " [2,] 2.165564 2.134785 2.108182 2.085184 2.065305 2.048398 2.035931 2.028503\n",
       " [3,] 1.913430 1.861710 1.817006 1.778355 1.744948 1.715714 1.687533 1.658602\n",
       " [4,] 1.720890 1.678676 1.642188 1.610628 1.583353 1.560264 1.544020 1.535726\n",
       " [5,] 2.023486 2.008379 1.995321 1.984021 1.974256 1.966286 1.963029 1.965845\n",
       " [6,] 2.572118 2.552762 2.536031 2.521581 2.509089 2.498515 2.491212 2.487810\n",
       " [7,] 2.069095 2.046385 2.026755 2.009779 1.995107 1.982963 1.976661 1.977740\n",
       " [8,] 2.369273 2.324912 2.286567 2.253431 2.224789 2.200388 2.182157 2.170912\n",
       " [9,] 2.475547 2.464922 2.455739 2.447807 2.440950 2.434740 2.427167 2.417185\n",
       "[10,] 2.488598 2.479836 2.472263 2.465723 2.460069 2.454576 2.445079 2.429455\n",
       "[11,] 2.694332 2.723531 2.748770 2.770593 2.789454 2.806156 2.823797 2.844056\n",
       "[12,] 2.111992 2.088691 2.068550 2.051134 2.036081 2.023587 2.016829 2.017282\n",
       "[13,] 2.549342 2.576609 2.600177 2.620550 2.638159 2.653771 2.670366 2.689538\n",
       "[14,] 2.375203 2.372537 2.370233 2.368241 2.366520 2.365351 2.366865 2.372109\n",
       "[15,] 2.724118 2.719294 2.715125 2.711536 2.708431 2.705178 2.697962 2.684879\n",
       "[16,] 2.629219 2.687553 2.737975 2.781558 2.819229 2.851972 2.881718 2.909637\n",
       "[17,] 2.755654 2.804983 2.847621 2.884456 2.916297 2.943272 2.962126 2.971383\n",
       "[18,] 2.365757 2.318191 2.277076 2.241546 2.210834 2.184773 2.166139 2.156159\n",
       "[19,] 3.008894 3.025252 3.039392 3.051636 3.062216 3.071624 3.081990 3.094499\n",
       "           s17      s18      s19      s20      s21      s22       s23       s24\n",
       " [1,] 1.114899 1.088151 1.064792 1.042724 1.022909 1.005535 0.9906115 0.9776038\n",
       " [2,] 2.022788 2.017696 2.012833 2.004227 1.994597 1.985336 1.9773456 1.9704294\n",
       " [3,] 1.632643 1.609616 1.587928 1.559406 1.532522 1.508481 1.4877431 1.4697712\n",
       " [4,] 1.529780 1.523680 1.515487 1.497442 1.482472 1.470177 1.4596468 1.4504378\n",
       " [5,] 1.969473 1.971955 1.972109 1.960924 1.948474 1.936697 1.9265865 1.9177698\n",
       " [6,] 2.485470 2.483525 2.482106 2.487482 2.496792 2.506890 2.5155595 2.5231077\n",
       " [7,] 1.980050 1.981468 1.980939 1.970146 1.958019 1.946480 1.9365582 1.9279297\n",
       " [8,] 2.162129 2.153731 2.144079 2.122060 2.099445 2.078499 2.0603848 2.0447609\n",
       " [9,] 2.407833 2.398351 2.385976 2.355587 2.326880 2.301386 2.2793621 2.2602985\n",
       "[10,] 2.414392 2.400491 2.385845 2.360077 2.335712 2.313964 2.2951590 2.2788912\n",
       "[11,] 2.862615 2.879269 2.895504 2.914827 2.929854 2.941877 2.9522313 2.9612065\n",
       "[12,] 2.019001 2.020549 2.022062 2.031554 2.046107 2.061560 2.0749311 2.0864585\n",
       "[13,] 2.707125 2.722652 2.737037 2.753039 2.766737 2.778417 2.7885031 2.7972091\n",
       "[14,] 2.377469 2.382699 2.389004 2.405576 2.423312 2.439998 2.4543991 2.4668538\n",
       "[15,] 2.672123 2.660804 2.650172 2.634307 2.617863 2.602457 2.5890854 2.5775743\n",
       "[16,] 2.934242 2.955301 2.972860 2.982776 2.989321 2.994146 2.9983365 3.0018949\n",
       "[17,] 2.977924 2.982679 2.984050 2.969561 2.953129 2.937513 2.9241390 2.9124554\n",
       "[18,] 2.148808 2.141941 2.134492 2.123917 2.116269 2.110464 2.1054194 2.1011040\n",
       "[19,] 3.106040 3.116263 3.125889 3.143902 3.165017 3.185637 3.2033561 3.2187614\n",
       "            s25       s26      s27       s28       s29       s30       s31\n",
       " [1,] 0.9658833 0.9522424 0.937302 0.9244012 0.9132818 0.9036732 0.8953563\n",
       " [2,] 1.9646736 1.9623058 1.962620 1.9628490 1.9630602 1.9632439 1.9633970\n",
       " [3,] 1.4542118 1.4408757 1.429459 1.4195915 1.4110646 1.4036945 1.3973230\n",
       " [4,] 1.4418866 1.4287781 1.412296 1.3981450 1.3859044 1.3753232 1.3661820\n",
       " [5,] 1.9100691 1.9032117 1.897115 1.8918434 1.8872808 1.8833365 1.8799289\n",
       " [6,] 2.5291023 2.5267388 2.517862 2.5103962 2.5039147 2.4983101 2.4934804\n",
       " [7,] 1.9204930 1.9147229 1.910338 1.9065343 1.9032415 1.9003948 1.8979355\n",
       " [8,] 2.0317235 2.0246633 2.022356 2.0203244 2.0185484 2.0170116 2.0156901\n",
       " [9,] 2.2421571 2.2054105 2.154577 2.1110931 2.0733052 2.0406252 2.0124604\n",
       "[10,] 2.2653563 2.2590407 2.258455 2.2579143 2.2574545 2.2570578 2.2567114\n",
       "[11,] 2.9696044 2.9839382 3.002728 3.0188675 3.0328607 3.0449597 3.0554000\n",
       "[12,] 2.0962721 2.1035872 2.108873 2.1134869 2.1175429 2.1210546 2.1240664\n",
       "[13,] 2.8053364 2.8195165 2.838256 2.8543496 2.8683226 2.8804058 2.8908252\n",
       "[14,] 2.4784523 2.4985761 2.525121 2.5479044 2.5677208 2.5848601 2.5996269\n",
       "[15,] 2.5683722 2.5676918 2.573675 2.5787829 2.5832076 2.5870330 2.5903351\n",
       "[16,] 3.0049301 3.0072486 3.008990 3.0105349 3.0118575 3.0129995 3.0139919\n",
       "[17,] 2.9023412 2.8957753 2.892083 2.8887395 2.8858294 2.8833122 2.8811394\n",
       "[18,] 2.0971504 2.0897931 2.079858 2.0713952 2.0640465 2.0576917 2.0522139\n",
       "[19,] 3.2316091 3.2350430 3.231057 3.2278564 3.2250491 3.2226191 3.2205391\n",
       "            s32       s33      s34       s35       s36       s37       s38\n",
       " [1,] 0.8881481 0.8819484 0.876590 0.8719448 0.8679208 0.8644642 0.8615458\n",
       " [2,] 1.9635199 1.9636410 1.963746 1.9638283 1.9638939 1.9639640 1.9648063\n",
       " [3,] 1.3918140 1.3870551 1.382942 1.3793850 1.3763098 1.3736539 1.3719231\n",
       " [4,] 1.3582884 1.3514534 1.345545 1.3404476 1.3360472 1.3322293 1.3281782\n",
       " [5,] 1.8769863 1.8744385 1.872236 1.8703344 1.8686917 1.8672691 1.8665384\n",
       " [6,] 2.4893302 2.4857044 2.482570 2.4798861 2.4775829 2.4755511 2.4746345\n",
       " [7,] 1.8958118 1.8939731 1.892384 1.8910106 1.8898243 1.8887978 1.8885677\n",
       " [8,] 2.0145589 2.0135636 2.012703 2.0119658 2.0113332 2.0107757 2.0115364\n",
       " [9,] 1.9882520 1.9671126 1.948837 1.9331555 1.9196763 1.9078423 1.8939449\n",
       "[10,] 2.2564062 2.2561516 2.255932 2.2557360 2.2555633 2.2554228 2.2541529\n",
       "[11,] 3.0643952 3.0722159 3.078977 3.0847955 3.0898090 3.0941818 3.0987067\n",
       "[12,] 2.1266310 2.1289088 2.130879 2.1325554 2.1339874 2.1352664 2.1373742\n",
       "[13,] 2.8997903 2.9076040 2.914359 2.9201640 2.9251599 2.9295312 2.9322298\n",
       "[14,] 2.6123119 2.6234005 2.632987 2.6412107 2.6482778 2.6544858 2.6598938\n",
       "[15,] 2.5931820 2.5956542 2.597791 2.5996309 2.6012161 2.6025983 2.6047574\n",
       "[16,] 3.0148583 3.0155936 3.016229 3.0167855 3.0172716 3.0176798 3.0161501\n",
       "[17,] 2.8792667 2.8776400 2.876234 2.8750155 2.8739612 2.8730543 2.8712863\n",
       "[18,] 2.0475041 2.0433937 2.039840 2.0367917 2.0341715 2.0318703 2.0302354\n",
       "[19,] 3.2187749 3.2171967 3.215832 3.2146859 3.2137173 3.2128260 3.2087503\n",
       "            s39       s40       s41       s42       s43       s44       s45\n",
       " [1,] 0.8591603 0.8571547 0.8553763 0.8538312 0.8525307 0.8514016 0.8504063\n",
       " [2,] 1.9660408 1.9673258 1.9683606 1.9692369 1.9700497 1.9707383 1.9712923\n",
       " [3,] 1.3708244 1.3700497 1.3693224 1.3686812 1.3681691 1.3677174 1.3672983\n",
       " [4,] 1.3243264 1.3208535 1.3178907 1.3153429 1.3131132 1.3111979 1.3095710\n",
       " [5,] 1.8662188 1.8660771 1.8659107 1.8657584 1.8656542 1.8655572 1.8654536\n",
       " [6,] 2.4746046 2.4749541 2.4751923 2.4753836 2.4756204 2.4758208 2.4759602\n",
       " [7,] 1.8887846 1.8891523 1.8894128 1.8896257 1.8898478 1.8900300 1.8901593\n",
       " [8,] 2.0129708 2.0145540 2.0158310 2.0169123 2.0179113 2.0187575 2.0194387\n",
       " [9,] 1.8796616 1.8663858 1.8553244 1.8458680 1.8373886 1.8301424 1.8241158\n",
       "[10,] 2.2522991 2.2503582 2.2487692 2.2474165 2.2461768 2.2451197 2.2442537\n",
       "[11,] 3.1030394 3.1069546 3.1102656 3.1131077 3.1156190 3.1177736 3.1195916\n",
       "[12,] 2.1400867 2.1428319 2.1450566 2.1469449 2.1487078 2.1502105 2.1514296\n",
       "[13,] 2.9338555 2.9349297 2.9359104 2.9367693 2.9374711 2.9380844 2.9386398\n",
       "[14,] 2.6646908 2.6688655 2.6723861 2.6754057 2.6780894 2.6803915 2.6823280\n",
       "[15,] 2.6071930 2.6095440 2.6115043 2.6131793 2.6146807 2.6159634 2.6170289\n",
       "[16,] 3.0135629 3.0107684 3.0085237 3.0066254 3.0048521 3.0033498 3.0021460\n",
       "[17,] 2.8688389 2.8662834 2.8641797 2.8623884 2.8607290 2.8593072 2.8581399\n",
       "[18,] 2.0292001 2.0284985 2.0278672 2.0273162 2.0268699 2.0264842 2.0261387\n",
       "[19,] 3.2033159 3.1978184 3.1933500 3.1895554 3.1860845 3.1831408 3.1807497\n",
       "            s46       s47       s48      s49       s50\n",
       " [1,] 0.8495451 0.8489281 0.8482851 0.847670 0.8471997\n",
       " [2,] 1.9717508 1.9722440 1.9726100 1.972900 1.9732028\n",
       " [3,] 1.3669246 1.3666917 1.3664270 1.366167 1.3659862\n",
       " [4,] 1.3081876 1.3070000 1.3059431 1.305005 1.3041847\n",
       " [5,] 1.8653568 1.8653402 1.8652751 1.865194 1.8651619\n",
       " [6,] 2.4760725 2.4763283 2.4764399 2.476467 2.4765339\n",
       " [7,] 1.8902586 1.8904202 1.8905082 1.890561 1.8906482\n",
       " [8,] 2.0199989 2.0205575 2.0210118 2.021396 2.0217706\n",
       " [9,] 1.8190287 1.8140905 1.8101639 1.806913 1.8037837\n",
       "[10,] 2.2435253 2.2427525 2.2421822 2.241738 2.2412853\n",
       "[11,] 3.1211376 3.1225567 3.1237377 3.124742 3.1256631\n",
       "[12,] 2.1524554 2.1536482 2.1544562 2.155034 2.1556672\n",
       "[13,] 2.9391301 2.9394858 2.9398332 2.940156 2.9404093\n",
       "[14,] 2.6839766 2.6855593 2.6868159 2.687850 2.6888290\n",
       "[15,] 2.6179235 2.6187537 2.6194535 2.620056 2.6206102\n",
       "[16,] 3.0011520 3.0000688 2.9992678 2.998638 2.9979809\n",
       "[17,] 2.8571543 2.8560828 2.8552992 2.854708 2.8541239\n",
       "[18,] 2.0258378 2.0256328 2.0254226 2.025216 2.0250434\n",
       "[19,] 3.1787622 3.1767143 3.1751504 3.173879 3.1725728\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@rget lasso_prediction  # Output from R `bestsubset` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×39 Matrix{Float64}:\n",
       " 2.55277  2.26104  2.0193   1.82062  1.68352  …  0.848702  0.847819  0.8472\n",
       " 2.55277  2.46932  2.40016  2.34204  2.28046     1.97244   1.9728    1.9732\n",
       " 2.55277  2.40748  2.28709  2.18724  2.10324     1.36661   1.36622   1.36599\n",
       " 2.55277  2.33066  2.14661  1.99491  1.88305     1.30655   1.30527   1.30418\n",
       " 2.55277  2.40257  2.27811  2.17495  2.08917     1.86534   1.8652    1.86516\n",
       " 2.55277  2.59497  2.62994  2.65661  2.64058  …  2.47644   2.47645   2.47653\n",
       " 2.55277  2.42699  2.32276  2.23607  2.15913     1.89049   1.89053   1.89065\n",
       " 2.55277  2.5547   2.55629  2.55579  2.52516     2.02077   2.02128   2.02177\n",
       " 2.55277  2.55183  2.55105  2.54862  2.51695     1.81218   1.80791   1.80378\n",
       " 2.55277  2.55413  2.55525  2.55437  2.52353     2.24245   2.24188   2.24129\n",
       " 2.55277  2.58034  2.60319  2.62     2.59867  …  3.1231    3.12445   3.12566\n",
       " 2.55277  2.44233  2.35082  2.27448  2.20311     2.15412   2.15483   2.15567\n",
       " 2.55277  2.53305  2.5167   2.50159  2.46311     2.93962   2.94008   2.94041\n",
       " 2.55277  2.5083   2.47146  2.43965  2.39219     2.68617   2.68754   2.68883\n",
       " 2.55277  2.63003  2.69405  2.74439  2.74107     2.61907   2.61988   2.62061\n",
       " 2.55277  2.52426  2.50064  2.4796   2.43793  …  2.99964   2.99885   2.99798\n",
       " 2.55277  2.52679  2.50526  2.49295  2.57439     2.85566   2.85489   2.85412\n",
       " 2.55277  2.55722  2.5609   2.5621   2.53238     2.02556   2.02527   2.02504\n",
       " 2.55277  2.70274  2.82701  2.92641  2.94945     3.17592   3.17429   3.17257"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pred  # Output by our julia implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m47.982 μs\u001b[22m\u001b[39m … \u001b[35m  8.696 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 99.04%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m52.410 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m59.079 μs\u001b[22m\u001b[39m ± \u001b[32m201.669 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m8.32% ±  2.43%\n",
       "\n",
       "  \u001b[39m▃\u001b[39m▅\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▅\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m \u001b[39m█\n",
       "  48 μs\u001b[90m         \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      96.4 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m51.25 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m68\u001b[39m."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "bm = @benchmark prediction_glmnet($X_train, $y_train, $X_test, nlambda=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "Unit: milliseconds\n",
       "        expr     min       lq     mean   median       uq      max neval\n",
       " lasso(x, y) 1.08866 1.235629 1.602025 1.405532 1.605285 6.464913   100\n"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(microbenchmark)\n",
    "Rbm <- microbenchmark(lasso(x,y))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(bestsubset)\n",
    "x <- $X_train\n",
    "y <- $y_train\n",
    "xtest <- $X_test\n",
    "relaxlasso.obj = lasso(x,y, nrelax = 3)\n",
    "relaxlasso_beta = as.matrix(coef(relaxlasso.obj))[-1, ] # store betas except intercepts\n",
    "relaxlasso_prediction  = predict(relaxlasso.obj,newx=xtest)\n",
    "\"\"\"\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pred, my_betas , λs = prediction_glmnet(X_train, y_train, X_test, nlambda = 50, nrelax = 3) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×150 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  0.095222  0.398613  0.702004  …   0.557367     0.558751\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.654719     0.65463\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0          -0.0219284   -0.0220767\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.0970822    0.0975977\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.822432     0.824548\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0       …  -0.125466    -0.12749\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0          -0.0293877   -0.0324888\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.00468846   0.00479077"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@rget relaxlasso_beta  # Output from R `bestsubset` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×117 Matrix{Float64}:\n",
       " 0.0  0.0  0.0  0.120293  0.411148  0.702004  …   0.557367     0.558751\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.654719     0.65463\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0          -0.0219284   -0.0220767\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.0970822    0.0975977\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.822432     0.824548\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0       …  -0.125466    -0.12749\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0          -0.0293877   -0.0324888\n",
       " 0.0  0.0  0.0  0.0       0.0       0.0           0.00468846   0.00479077"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×150 Matrix{Float64}:\n",
       " 2.55277  2.55277  2.55277  2.32184  1.58607  …  0.8472   0.845785  0.844371\n",
       " 2.55277  2.55277  2.55277  2.48671  2.27624     1.9732   1.97431   1.97542\n",
       " 2.55277  2.55277  2.55277  2.43776  2.07134     1.36599  1.36552   1.36506\n",
       " 2.55277  2.55277  2.55277  2.37695  1.81676     1.30418  1.3015    1.29882\n",
       " 2.55277  2.55277  2.55277  2.43388  2.05507     1.86516  1.86512   1.86508\n",
       " 2.55277  2.55277  2.55277  2.58617  2.69261  …  2.47653  2.477     2.47746\n",
       " 2.55277  2.55277  2.55277  2.4532   2.13596     1.89065  1.89102   1.89139\n",
       " 2.55277  2.55277  2.55277  2.55429  2.55915     2.02177  2.02314   2.02451\n",
       " 2.55277  2.55277  2.55277  2.55203  2.54966     1.80378  1.79305   1.78231\n",
       " 2.55277  2.55277  2.55277  2.55384  2.55727     2.24129  2.23965   2.23801\n",
       " 2.55277  2.55277  2.55277  2.5746   2.64414  …  3.12566  3.12874   3.13181\n",
       " 2.55277  2.55277  2.55277  2.46535  2.18681     2.15567  2.15806   2.16046\n",
       " 2.55277  2.55277  2.55277  2.53716  2.48741     2.94041  2.9411    2.94178\n",
       " 2.55277  2.55277  2.55277  2.51757  2.40542     2.68883  2.69214   2.69545\n",
       " 2.55277  2.55277  2.55277  2.61393  2.80879     2.62061  2.62252   2.62444\n",
       " 2.55277  2.55277  2.55277  2.5302   2.45831  …  2.99798  2.99552   2.99307\n",
       " 2.55277  2.55277  2.55277  2.5322   2.46667     2.85412  2.8519    2.84967\n",
       " 2.55277  2.55277  2.55277  2.55629  2.56751     2.02504  2.02461   2.02418\n",
       " 2.55277  2.55277  2.55277  2.67148  3.04972     3.17257  3.16796   3.16335"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@rget relaxlasso_prediction # Output from R `bestsubset` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19×117 Matrix{Float64}:\n",
       " 2.55277  2.55277  2.55277  2.26104  1.55567  …  0.8472   0.845785  0.844371\n",
       " 2.55277  2.55277  2.55277  2.46932  2.26754     1.9732   1.97431   1.97542\n",
       " 2.55277  2.55277  2.55277  2.40748  2.0562      1.36599  1.36552   1.36506\n",
       " 2.55277  2.55277  2.55277  2.33066  1.79362     1.30418  1.3015    1.29882\n",
       " 2.55277  2.55277  2.55277  2.40257  2.03942     1.86516  1.86512   1.86508\n",
       " 2.55277  2.55277  2.55277  2.59497  2.697    …  2.47653  2.477     2.47746\n",
       " 2.55277  2.55277  2.55277  2.42699  2.12286     1.89065  1.89102   1.89139\n",
       " 2.55277  2.55277  2.55277  2.5547   2.55935     2.02177  2.02314   2.02451\n",
       " 2.55277  2.55277  2.55277  2.55183  2.54956     1.80378  1.79305   1.78231\n",
       " 2.55277  2.55277  2.55277  2.55413  2.55742     2.24129  2.23965   2.23801\n",
       " 2.55277  2.55277  2.55277  2.58034  2.64702  …  3.12566  3.12874   3.13181\n",
       " 2.55277  2.55277  2.55277  2.44233  2.1753      2.15567  2.15806   2.16046\n",
       " 2.55277  2.55277  2.55277  2.53305  2.48536     2.94041  2.9411    2.94178\n",
       " 2.55277  2.55277  2.55277  2.5083   2.40079     2.68883  2.69214   2.69545\n",
       " 2.55277  2.55277  2.55277  2.63003  2.81684     2.62061  2.62252   2.62444\n",
       " 2.55277  2.55277  2.55277  2.52426  2.45534  …  2.99798  2.99552   2.99307\n",
       " 2.55277  2.55277  2.55277  2.52679  2.46397     2.85412  2.8519    2.84967\n",
       " 2.55277  2.55277  2.55277  2.55722  2.56797     2.02504  2.02461   2.02418\n",
       " 2.55277  2.55277  2.55277  2.70274  3.06534     3.17257  3.16796   3.16335"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pred    # Output by our julia implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
